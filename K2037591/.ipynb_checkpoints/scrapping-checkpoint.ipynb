{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "ArwIThQ1X-MT",
    "outputId": "72be3fb4-8bce-4fb6-9f84-8ae8689e99ba"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\2/ipykernel_5948/4195100635.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# import modules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "# Python Script to Extract tweets of a\n",
    "# particular Hashtag using Tweepy and Pandas\n",
    "\n",
    "\n",
    "# import modules\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "\n",
    "\n",
    "# function to display data of each tweet\n",
    "def printtweetdata(n, ith_tweet):\n",
    "\tprint()\n",
    "\tprint(f\"Tweet {n}:\")\n",
    "\tprint(f\"Username:{ith_tweet[0]}\")\n",
    "\tprint(f\"Description:{ith_tweet[1]}\")\n",
    "\tprint(f\"Location:{ith_tweet[2]}\")\n",
    "\tprint(f\"Following Count:{ith_tweet[3]}\")\n",
    "\tprint(f\"Follower Count:{ith_tweet[4]}\")\n",
    "\tprint(f\"Total Tweets:{ith_tweet[5]}\")\n",
    "\tprint(f\"Retweet Count:{ith_tweet[6]}\")\n",
    "\tprint(f\"Tweet Text:{ith_tweet[7]}\")\n",
    "\tprint(f\"Hashtags Used:{ith_tweet[8]}\")\n",
    "\n",
    "\n",
    "# function to perform data extraction\n",
    "def scrape(words, date_since, numtweet, filename):\n",
    "\t\n",
    "\t# Creating DataFrame using pandas\n",
    "\tdb = pd.DataFrame(columns=['username', 'description', 'location', 'following',\n",
    "\t\t\t\t\t\t\t'followers', 'totaltweets', 'retweetcount', 'text', 'hashtags'])\n",
    "\t\n",
    "\t# We are using .Cursor() to search through twitter for the required tweets.\n",
    "\t# The number of tweets can be restricted using .items(number of tweets)\n",
    "\ttweets = tweepy.Cursor(api.search, q=words, lang=\"en\",\n",
    "\t\t\t\t\t\tsince=date_since, tweet_mode='extended').items(numtweet)\n",
    "\t\n",
    "\t# .Cursor() returns an iterable object. Each item in\n",
    "\t# the iterator has various attributes that you can access to\n",
    "\t# get information about each tweet\n",
    "\tlist_tweets = [tweet for tweet in tweets]\n",
    "\t\n",
    "\t# Counter to maintain Tweet Count\n",
    "\ti = 1\n",
    "\t\n",
    "\t# we will iterate over each tweet in the list for extracting information about each tweet\n",
    "\tfor tweet in list_tweets:\n",
    "\t\tusername = tweet.user.screen_name\n",
    "\t\tdescription = tweet.user.description\n",
    "\t\tlocation = tweet.user.location\n",
    "\t\tfollowing = tweet.user.friends_count\n",
    "\t\tfollowers = tweet.user.followers_count\n",
    "\t\ttotaltweets = tweet.user.statuses_count\n",
    "\t\tretweetcount = tweet.retweet_count\n",
    "\t\thashtags = tweet.entities['hashtags']\n",
    "\t\t\n",
    "\t\t# Retweets can be distinguished by a retweeted_status attribute,\n",
    "\t\t# in case it is an invalid reference, except block will be executed\n",
    "\t\ttry:\n",
    "\t\t\ttext = tweet.retweeted_status.full_text\n",
    "\t\texcept AttributeError:\n",
    "\t\t\ttext = tweet.full_text\n",
    "\t\thashtext = list()\n",
    "\t\tfor j in range(0, len(hashtags)):\n",
    "\t\t\thashtext.append(hashtags[j]['text'])\n",
    "\t\t\n",
    "\t\t# Here we are appending all the extracted information in the DataFrame\n",
    "\t\tith_tweet = [username, description, location, following,\n",
    "\t\t\t\t\tfollowers, totaltweets, retweetcount, text, hashtext]\n",
    "\t\tdb.loc[len(db)] = ith_tweet\n",
    "\t\t\n",
    "\t\t# Function call to print tweet data on screen\n",
    "\t\tprinttweetdata(i, ith_tweet)\n",
    "\t\ti = i+1\n",
    "\tpath = '/content/drive/MyDrive/Techies/KARTIK 11-09-2021/Dataset/'+filename\n",
    "\t\n",
    "\t# we will save our database as a CSV file.\n",
    "\tdb.to_csv('/content/drive/MyDrive/Techies/KARTIK 11-09-2021/data.csv')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t\n",
    "  # Enter your own credentials obtained\n",
    "  # from your developer account\n",
    "  consumer_key=\"ArvY8sU6HDZSuGk9nMADCd1Za\"\n",
    "  consumer_secret=\"WhhxixavlxGgAsr6nHwwjmsEDdNCBGCC2LxHJWLl0Tho5OcTKe\"\n",
    "  access_token=\"2415738176-GCKuN5W25sftYfjOMXMgA1UXaS6kHkl8gYnMWGm\"\n",
    "  access_token_secret=\"GBzgC4NrDA4XhCf7CS6md1zQuNmm0o458rhJSqfz3PFki\"\n",
    "\n",
    "  auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "  auth.set_access_token(access_token,access_token_secret)\n",
    "  api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "  # Enter Hashtag and initial date\n",
    "  print(\"Enter Twitter HashTag to search for\")\n",
    "  words = ['crypto']\n",
    "  print(\"Enter Date since The Tweets are required in yyyy-mm--dd\")\n",
    "  date_since = 2019-12-30\n",
    "  for word in words:\n",
    "    # number of tweets you want to extract in one run\n",
    "    numtweet = 1\n",
    "    filename = word+'.csv'\n",
    "    scrape(word, date_since, numtweet, filename)\n",
    "    print('Scraping has completed for ',word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BW6lEFIVeZsn"
   },
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment_polarity = blob.sentiment.polarity\n",
    "    sentiment_subjectivity = blob.sentiment.subjectivity\n",
    "    if sentiment_polarity > 0:\n",
    "        sentiment_label = 1\n",
    "    elif sentiment_polarity < 0:\n",
    "        sentiment_label = -1\n",
    "    else:\n",
    "        sentiment_label = 0\n",
    "    result = {'polarity':sentiment_polarity,\n",
    "              'subjectivity':sentiment_subjectivity,\n",
    "              'sentiment':sentiment_label}\n",
    "    return result\n",
    "\n",
    "sent = get_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAOuFxZQZ721"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1z_P55VaEgo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "scrapping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
